{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect data and add geometry\n",
    "\n",
    "This is the most important step of all, since a bad geometry will invalidate every subsequent processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import rsf.api as sf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set a custom DATAPATH to Madagascar\n",
    "%env DATAPATH=/home/rodrigo/Projetos/Viking/DATAPATH/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = 'seismic.segy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a data sample of 200 traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = 'sample_agc.rsf'\n",
    "\n",
    "!sfsegyread n2=200 read=d < {raw_data} | sfagc > {data_sample}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sfin {data_sample}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = sf.Input(data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = data_sample.int('n1')\n",
    "n2 = data_sample.int('n2')\n",
    "d1 = data_sample.float('d1')\n",
    "o1 = data_sample.float('o1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((n2, n1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample.read(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc = np.percentile(data.ravel(), 99)\n",
    "t = np.arange(n1) * d1 + o1\n",
    "extent = [0, n2, t[-1], o1]\n",
    "plt.figure(figsize=(4, 6))\n",
    "plt.imshow(data.clip(-perc, perc).T, aspect='auto', extent=extent)\n",
    "\n",
    "plt.ylabel('t (s)')\n",
    "plt.xlabel('traces')\n",
    "\n",
    "plt.title('raw data sample w/ AGC')\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the data above really well, every shot seem to be around 120 traces long. We also see coherent events, so we know that our data file is not corrupted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect all the header and text headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_raw = 'line_12_header_raw.rsf'\n",
    "text_header = 'line_12_text_header.txt'\n",
    "\n",
    "!sfsegyread read=h < {raw_data} tfile={header_raw} hfile={text_header} > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat {text_header} | fold -w 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sfheaderattr < {header_raw}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I suspected, we have 120 traces per shot (tracf), also the geometry seem to be fairly complete, with cdp, shotpoint and offset all set. The text header does not provide us with any additional information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to convert the header to floating point before reading with python\n",
    "header_float = 'line_12_header_float.rsf'\n",
    "\n",
    "!sfdd type=float < {header_raw} > {header_float}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = sf.Input(header_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = header.int('n1')\n",
    "n2 = header.int('n2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.zeros((n2, n1), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header.read(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over file w/ SEG-Y keyword/index relation\n",
    "keys = {}\n",
    "\n",
    "for index, row in pd.read_csv('keys.txt', sep=' ').iterrows():\n",
    "    keys[row.key] = row.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create a DataFrame with the line header. Pandas DataFrames are easier to manipulate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = pd.DataFrame()\n",
    "\n",
    "for k in keys:\n",
    "    header[k] = data[:,keys[k]]\n",
    "    \n",
    "header[['offset', 'ep', 'cdp', 'sx', 'gx']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating the line geometry with some QC plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(header.ep, header.gx, '.', label='group')\n",
    "plt.plot(header.ep, header.sx, '.', label='source')\n",
    "\n",
    "\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.xlabel('shotpoint number')\n",
    "plt.ylabel('distance along the line (m)')\n",
    "\n",
    "plt.axis('tight')\n",
    "sns.despine(offset=5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(header.ep, header.offset, ',')\n",
    "\n",
    "plt.xlabel('shotpoint number')\n",
    "plt.ylabel('offset (m)')\n",
    "\n",
    "plt.axis('tight')\n",
    "sns.despine(offset=5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To properly manipulate the line geometry we need some extra keywords, like sequential shotpoint, proper cdpt, group number and trace number with group ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(header.cdp, header.ep, ',')\n",
    "\n",
    "\n",
    "plt.xlabel('cdp')\n",
    "plt.ylabel('ep')\n",
    "\n",
    "plt.axis('tight')\n",
    "sns.despine(offset=5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recovering the original group number\n",
    "\n",
    "This survey is stack array, since 262 m/25 m ~ 10.5, so we can recover the group number with the following expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header['grnofr'] = header.ep - 10.5 - np.abs(header.tracf - 120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(header.grnofr, header.ep, ',')\n",
    "\n",
    "plt.xlabel('grnofr')\n",
    "plt.ylabel('ep')\n",
    "\n",
    "plt.axis('tight')\n",
    "sns.despine(offset=5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = (header['ep'] - header['grnofr'])  * 25\n",
    "# 0.5 m is the difference between the real minimum offset and\n",
    "# the offset to make this survey a perfect stack array\n",
    "offset -= 0.5\n",
    "# Also, all offsets are negative\n",
    "offset = -offset\n",
    "\n",
    "# Lets check if the provided offset and calculated offset matches\n",
    "np.allclose(offset, header['offset'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets check if the sequential CDP provided and our\n",
    "# calculated CDP matches\n",
    "\n",
    "cdp = (header.ep + header.grnofr)/2\n",
    "bins = cdp.unique()\n",
    "np.allclose(header.cdp, np.digitize(cdp, bins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets create a sequential group number for sorting purposes\n",
    "bins = header.grnofr.unique()\n",
    "header['grnors'] = np.digitize(header.grnofr, bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also need a equivalent to CDPT for for common group sorting\n",
    "\n",
    "header['offset_bin'] = header.grnofr - header.ep\n",
    "header['grnlof'] = header.groupby('grnors').offset_bin.apply(np.argsort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there is skips, we also need a sequential shotpoint\n",
    "# lets recicle the fldr keyword\n",
    "bins = header.ep.unique()\n",
    "fldr = np.digitize(header.ep, bins)\n",
    "header['fldr'] = fldr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recalculate a proper CDPT\n",
    "\n",
    "The original CDPT has skips on it, we need a truly sequential CDPT, otherwise the data in CDP domain will be filled with many zeroed traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header['cdpt'] = header.groupby('cdp').offset_bin.apply(np.argsort)\n",
    "header.drop('offset_bin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(header.cdp, header.cdpt, ',')\n",
    "\n",
    "\n",
    "plt.xlabel('cdp')\n",
    "plt.ylabel('cdpt')\n",
    "\n",
    "plt.axis('tight')\n",
    "sns.despine(offset=5)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometry summary\n",
    "\n",
    "With the keywords listed below properly set we can sort the data to any domain we want (i.e. Common Mid Point Gather, Common Shotpoint Gather, Common Receiver Group Gather).\n",
    "\n",
    "| keyword | usage |\n",
    "|------|------|\n",
    "| fldr | sequential shotpoint |\n",
    "| ep | field shotpoint |\n",
    "| tracf | trace number within common shot ensemble |\n",
    "| cdp | sequential common mid point number |\n",
    "| cdpt | trace number within common mid point ensemble |\n",
    "| grnofr | field receiver group number |\n",
    "| grnors | sequential receiver group number |\n",
    "| grnlof | trace number within common receiver group ensemble |\n",
    "\n",
    "Now, all we need to do is write a RSF file with the improved header and also read all trace data. Also, there is no need to resample the data, since its already in 4 ms sampling rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in keys:\n",
    "    data[:,keys[k]] = header[k].values\n",
    "\n",
    "header_complete = 'line_12_header_complete.rsf'\n",
    "\n",
    "out = sf.Output(header_complete)\n",
    "out.put('n1', n1)\n",
    "out.put('n2', n2)\n",
    "\n",
    "out.write(data)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sfin {header_complete}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we just need to convert to int since Madagascar's sorting programs\n",
    "# only work with integer headers\n",
    "header_int = 'line_12_header_int.rsf'\n",
    "\n",
    "!sfdd type=int < {header_complete} > {header_int}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert full trace data to RSF format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_shot = 'line_12_csg_raw.rsf'\n",
    "\n",
    "!sfsegyread read=d < {raw_data} | sfput n2=120 n3=1001 > {common_shot}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sfin {common_shot}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
